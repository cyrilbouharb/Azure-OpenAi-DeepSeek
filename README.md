# Deploying and Using DeepSeek R1 with Azure AI Services

## Overview
This repository demonstrates how to deploy and use the **DeepSeek R1** model for reasoning with **Azure OpenAI, Azure AI Services, and Azure AI Foundry**. The project showcases how to:

- Deploy **DeepSeek R1** using Azure AI Foundry.
- Utilize **Azure Inference API** to call the model.
- Integrate the model into **VS Code** for local testing and development.
- Make API calls using Python and Azure SDKs.

## Prerequisites
You should have the following:
- An **Azure account** with access to Azure OpenAI Services.
- A deployed **DeepSeek R1** model in **Azure AI Foundry**.
- **Azure Inference API Key** and **Endpoint**.
- **Python 3.8+** installed.
- **VS Code** with Azure extensions (optional, but recommended)


https://github.com/user-attachments/assets/b0e74d1e-6c0c-4f16-ba9a-0b74cf6b0132

